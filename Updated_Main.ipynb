{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9d83418-d94c-4598-85ba-f2b1d7767184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\joman\\appdata\\roaming\\python\\python313\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\joman\\appdata\\roaming\\python\\python313\\site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\joman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\joman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\joman\\appdata\\roaming\\python\\python313\\site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\joman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\joman\\appdata\\roaming\\python\\python313\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\joman\\appdata\\roaming\\python\\python313\\site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.12.13-cp313-cp313-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\joman\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.7.0-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.5.0-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.3.2-cp313-cp313-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.20.1-cp313-cp313-win_amd64.whl.metadata (76 kB)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\joman\\appdata\\roaming\\python\\python313\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\joman\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\joman\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\joman\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joman\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\joman\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\joman\\appdata\\roaming\\python\\python313\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\joman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\joman\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\joman\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading aiohttp-3.12.13-cp313-cp313-win_amd64.whl (446 kB)\n",
      "Downloading multidict-6.5.0-cp313-cp313-win_amd64.whl (44 kB)\n",
      "Downloading yarl-1.20.1-cp313-cp313-win_amd64.whl (86 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.7.0-cp313-cp313-win_amd64.whl (43 kB)\n",
      "Downloading huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\n",
      "Downloading propcache-0.3.2-cp313-cp313-win_amd64.whl (40 kB)\n",
      "Downloading xxhash-3.5.0-cp313-cp313-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, propcache, multidict, fsspec, frozenlist, dill, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
      "\n",
      "  Attempting uninstall: fsspec\n",
      "\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "    Found existing installation: fsspec 2025.5.1\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "    Uninstalling fsspec-2025.5.1:\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "      Successfully uninstalled fsspec-2025.5.1\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "   --------- ------------------------------  3/13 [fsspec]\n",
      "   --------------- ------------------------  5/13 [dill]\n",
      "   --------------- ------------------------  5/13 [dill]\n",
      "   --------------------- ------------------  7/13 [yarl]\n",
      "   ------------------------ ---------------  8/13 [multiprocess]\n",
      "   ------------------------ ---------------  8/13 [multiprocess]\n",
      "   --------------------------- ------------  9/13 [huggingface-hub]\n",
      "   --------------------------- ------------  9/13 [huggingface-hub]\n",
      "   --------------------------- ------------  9/13 [huggingface-hub]\n",
      "   --------------------------- ------------  9/13 [huggingface-hub]\n",
      "   --------------------------- ------------  9/13 [huggingface-hub]\n",
      "   --------------------------- ------------  9/13 [huggingface-hub]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   --------------------------------- ------ 11/13 [aiohttp]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ------------------------------------ --- 12/13 [datasets]\n",
      "   ---------------------------------------- 13/13 [datasets]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.13 aiosignal-1.3.2 datasets-3.6.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 huggingface-hub-0.33.0 multidict-6.5.0 multiprocess-0.70.16 propcache-0.3.2 xxhash-3.5.0 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9558673b-4b1a-45f8-9eda-92fa5bc9eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8036e331-4a90-4d6e-bb3c-9e5db5a96ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joman\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████| 25/25 [44:10<00:00, 106.03s/files]\n",
      "Generating train split: 100%|█████████████████████████████████████| 7224600/7224600 [00:49<00:00, 147287.34 examples/s]\n",
      "Generating test split: 100%|█████████████████████████████████████████| 891924/891924 [00:12<00:00, 68845.23 examples/s]\n",
      "Generating val split: 100%|██████████████████████████████████████████| 802733/802733 [00:12<00:00, 65718.04 examples/s]\n",
      "Loading samples:  10%|█████▏                                                | 699871/7224600 [02:32<23:45, 4578.17it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "image file is truncated (29 bytes not processed)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Example: Show progress while converting to list\u001b[39;00m\n\u001b[32m      7\u001b[39m samples = []\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLoading samples\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\datasets\\arrow_dataset.py:2387\u001b[39m, in \u001b[36mDataset.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2385\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(pa_subtable.num_rows):\n\u001b[32m   2386\u001b[39m             pa_subtable_ex = pa_subtable.slice(i, \u001b[32m1\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2387\u001b[39m             formatted_output = \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2388\u001b[39m \u001b[43m                \u001b[49m\u001b[43mpa_subtable_ex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2389\u001b[39m \u001b[43m                \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2390\u001b[39m \u001b[43m                \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2391\u001b[39m \u001b[43m                \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2392\u001b[39m \u001b[43m                \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_output_all_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2393\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2394\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m formatted_output\n\u001b[32m   2395\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\datasets\\formatting\\formatting.py:653\u001b[39m, in \u001b[36mformat_table\u001b[39m\u001b[34m(table, key, formatter, format_columns, output_all_columns)\u001b[39m\n\u001b[32m    651\u001b[39m python_formatter = PythonFormatter(features=formatter.features)\n\u001b[32m    652\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m query_type == \u001b[33m\"\u001b[39m\u001b[33mcolumn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\datasets\\formatting\\formatting.py:406\u001b[39m, in \u001b[36mFormatter.__call__\u001b[39m\u001b[34m(self, pa_table, query_type)\u001b[39m\n\u001b[32m    404\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa.Table, query_type: \u001b[38;5;28mstr\u001b[39m) -> Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m query_type == \u001b[33m\"\u001b[39m\u001b[33mrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m406\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m query_type == \u001b[33m\"\u001b[39m\u001b[33mcolumn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    408\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_column(pa_table)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\datasets\\formatting\\formatting.py:455\u001b[39m, in \u001b[36mPythonFormatter.format_row\u001b[39m\u001b[34m(self, pa_table)\u001b[39m\n\u001b[32m    453\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    454\u001b[39m row = \u001b[38;5;28mself\u001b[39m.python_arrow_extractor().extract_row(pa_table)\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m row = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpython_features_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\datasets\\formatting\\formatting.py:223\u001b[39m, in \u001b[36mPythonFeaturesDecoder.decode_row\u001b[39m\u001b[34m(self, row)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, row: \u001b[38;5;28mdict\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.features \u001b[38;5;28;01melse\u001b[39;00m row\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\datasets\\features\\features.py:2101\u001b[39m, in \u001b[36mFeatures.decode_example\u001b[39m\u001b[34m(self, example, token_per_repo_id)\u001b[39m\n\u001b[32m   2086\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   2087\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[32m   2088\u001b[39m \n\u001b[32m   2089\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2097\u001b[39m \u001b[33;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[32m   2098\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   2100\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m-> \u001b[39m\u001b[32m2101\u001b[39m         column_name: \u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2102\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._column_requires_decoding[column_name]\n\u001b[32m   2103\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[32m   2104\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m column_name, (feature, value) \u001b[38;5;129;01min\u001b[39;00m zip_dict(\n\u001b[32m   2105\u001b[39m             {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example}, example\n\u001b[32m   2106\u001b[39m         )\n\u001b[32m   2107\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\datasets\\features\\features.py:1414\u001b[39m, in \u001b[36mdecode_nested_example\u001b[39m\u001b[34m(schema, obj, token_per_repo_id)\u001b[39m\n\u001b[32m   1411\u001b[39m \u001b[38;5;66;03m# Object with special decoding:\u001b[39;00m\n\u001b[32m   1412\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema, \u001b[33m\"\u001b[39m\u001b[33mdecode_example\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[33m\"\u001b[39m\u001b[33mdecode\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1413\u001b[39m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\datasets\\features\\image.py:187\u001b[39m, in \u001b[36mImage.decode_example\u001b[39m\u001b[34m(self, value, token_per_repo_id)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    186\u001b[39m     image = PIL.Image.open(BytesIO(bytes_))\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m \u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# to avoid \"Too many open files\" errors\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m image.getexif().get(PIL.Image.ExifTags.Base.Orientation) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    189\u001b[39m     image = PIL.ImageOps.exif_transpose(image)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\PIL\\ImageFile.py:386\u001b[39m, in \u001b[36mImageFile.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    381\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    382\u001b[39m         msg = (\n\u001b[32m    383\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mimage file is truncated \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    384\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(b)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m bytes not processed)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    385\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[32m    388\u001b[39m b = b + s\n\u001b[32m    389\u001b[39m n, err_code = decoder.decode(b)\n",
      "\u001b[31mOSError\u001b[39m: image file is truncated (29 bytes not processed)"
     ]
    }
   ],
   "source": [
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "#downloads the dataset\n",
    "ds = load_dataset(\"priyank-m/MJSynth_text_recognition\", split=\"train\")\n",
    "\n",
    "# Example: Show progress while converting to list\n",
    "samples = []\n",
    "for sample in tqdm(ds, desc=\"Loading samples\"):\n",
    "    samples.append(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "156e5362-99c8-45e9-b035-e002222d9e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading 60,000 samples: 100%|██████████████████████████████████████████████████| 60000/60000 [00:23<00:00, 2560.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Loaded 60000 samples from MJSynth.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load full dataset (will reuse cached version if already downloaded)\n",
    "ds = load_dataset(\"priyank-m/MJSynth_text_recognition\", split=\"train\")\n",
    "\n",
    "# Initialize an empty list to hold the first 60,000 samples\n",
    "subset_samples = []\n",
    "\n",
    "# Wrap tqdm around the loop to show a progress bar\n",
    "for i, sample in enumerate(tqdm(ds, total=60000, desc=\"Loading 60,000 samples\")):\n",
    "    if i >= 60000:\n",
    "        break\n",
    "    subset_samples.append(sample)\n",
    "\n",
    "# Now `subset_samples` contains the first 60,000 items\n",
    "print(f\"\\n✅ Loaded {len(subset_samples)} samples from MJSynth.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd02949f-2b77-4ad6-ae4a-da7aa367f39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': Image(mode=None, decode=True, id=None), 'label': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(ds.features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dbd6964-afdd-4507-9c64-1888f218643d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully saved 60,000 images to: mjsynth_subset\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import string\n",
    "\n",
    "# Constants\n",
    "CHARS = string.ascii_lowercase + string.digits\n",
    "DATA_DIR = \"mjsynth_subset\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Load dataset\n",
    "ds = load_dataset(\"priyank-m/MJSynth_text_recognition\", split=\"train\")\n",
    "\n",
    "# Save 60,000 filtered samples\n",
    "count = 0\n",
    "for i in range(len(ds)):\n",
    "    label = ds[i][\"label\"].lower()\n",
    "    if all(c in CHARS for c in label):  # filter out labels with unsupported characters\n",
    "        image = ds[i][\"image\"]\n",
    "        img_name = f\"{label}_{i}.jpg\"\n",
    "        image.save(os.path.join(DATA_DIR, img_name))\n",
    "        count += 1\n",
    "        if count == 60000:\n",
    "            break\n",
    "\n",
    "print(\"✅ Successfully saved 60,000 images to:\", DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0664ef9-845c-4e90-adca-6aa981d9fd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 Epoch 1: Loss = 3.0592\n",
      "[1] Predicted: ss | Actual: slenderize\n",
      "[2] Predicted:  | Actual: carla\n",
      "[3] Predicted: sos | Actual: bishops\n",
      "[4] Predicted:  | Actual: headbutting\n",
      "[5] Predicted:  | Actual: romanesque\n",
      "[6] Predicted: s | Actual: chipmunks\n",
      "[7] Predicted: ed | Actual: waterlily\n",
      "[8] Predicted: s | Actual: whoops\n",
      "[9] Predicted: s | Actual: precis\n",
      "[10] Predicted:  | Actual: babbler\n",
      "\n",
      " Word Accuracy: 0.00%\n",
      " Character Accuracy: 1.88%\n",
      "\n",
      "📚 Epoch 2: Loss = 1.1646\n",
      "[1] Predicted: slenderze | Actual: slenderize\n",
      "[2] Predicted: garla | Actual: carla\n",
      "[3] Predicted: bishops | Actual: bishops\n",
      "[4] Predicted: eadeuttng | Actual: headbutting\n",
      "[5] Predicted: ronanesoue | Actual: romanesque\n",
      "[6] Predicted: cmpmunks | Actual: chipmunks\n",
      "[7] Predicted: wacerlly | Actual: waterlily\n",
      "[8] Predicted: whoops | Actual: whoops\n",
      "[9] Predicted: precis | Actual: precis\n",
      "[10] Predicted: bbbler | Actual: babbler\n",
      "\n",
      " Word Accuracy: 41.33%\n",
      " Character Accuracy: 63.97%\n",
      "\n",
      "📚 Epoch 3: Loss = 0.6386\n",
      "[1] Predicted: slenderze | Actual: slenderize\n",
      "[2] Predicted: carua | Actual: carla\n",
      "[3] Predicted: bishops | Actual: bishops\n",
      "[4] Predicted: eadetting | Actual: headbutting\n",
      "[5] Predicted: ronanesaue | Actual: romanesque\n",
      "[6] Predicted: chgmunks | Actual: chipmunks\n",
      "[7] Predicted: wacerlly | Actual: waterlily\n",
      "[8] Predicted: whoops | Actual: whoops\n",
      "[9] Predicted: precis | Actual: precis\n",
      "[10] Predicted: babbler | Actual: babbler\n",
      "\n",
      " Word Accuracy: 52.68%\n",
      " Character Accuracy: 71.76%\n",
      "\n",
      "📚 Epoch 4: Loss = 0.5028\n",
      "[1] Predicted: slenderize | Actual: slenderize\n",
      "[2] Predicted: carla | Actual: carla\n",
      "[3] Predicted: bishops | Actual: bishops\n",
      "[4] Predicted: ieadeutng | Actual: headbutting\n",
      "[5] Predicted: romanesoue | Actual: romanesque\n",
      "[6] Predicted: chpmunks | Actual: chipmunks\n",
      "[7] Predicted: waterlly | Actual: waterlily\n",
      "[8] Predicted: whoops | Actual: whoops\n",
      "[9] Predicted: precis | Actual: precis\n",
      "[10] Predicted: bbdler | Actual: babbler\n",
      "\n",
      " Word Accuracy: 57.65%\n",
      " Character Accuracy: 76.04%\n",
      "\n",
      "📚 Epoch 5: Loss = 0.4212\n",
      "[1] Predicted: slenderze | Actual: slenderize\n",
      "[2] Predicted: carla | Actual: carla\n",
      "[3] Predicted: bishops | Actual: bishops\n",
      "[4] Predicted: headbuttng | Actual: headbutting\n",
      "[5] Predicted: ronanesoue | Actual: romanesque\n",
      "[6] Predicted: chpmunks | Actual: chipmunks\n",
      "[7] Predicted: waterlily | Actual: waterlily\n",
      "[8] Predicted: whoops | Actual: whoops\n",
      "[9] Predicted: precis | Actual: precis\n",
      "[10] Predicted: basler | Actual: babbler\n",
      "\n",
      " Word Accuracy: 59.32%\n",
      " Character Accuracy: 77.08%\n",
      "\n",
      "📚 Epoch 6: Loss = 0.3596\n",
      "[1] Predicted: slenderize | Actual: slenderize\n",
      "[2] Predicted: carla | Actual: carla\n",
      "[3] Predicted: bishops | Actual: bishops\n",
      "[4] Predicted: headbutting | Actual: headbutting\n",
      "[5] Predicted: romanesque | Actual: romanesque\n",
      "[6] Predicted: chipmunks | Actual: chipmunks\n",
      "[7] Predicted: wacerlily | Actual: waterlily\n",
      "[8] Predicted: whoops | Actual: whoops\n",
      "[9] Predicted: precis | Actual: precis\n",
      "[10] Predicted: babblet | Actual: babbler\n",
      "\n",
      " Word Accuracy: 62.58%\n",
      " Character Accuracy: 80.03%\n",
      "\n",
      "📚 Epoch 7: Loss = 0.3138\n",
      "[1] Predicted: slenderize | Actual: slenderize\n",
      "[2] Predicted: carla | Actual: carla\n",
      "[3] Predicted: bishops | Actual: bishops\n",
      "[4] Predicted: ieadbuiting | Actual: headbutting\n",
      "[5] Predicted: romanesque | Actual: romanesque\n",
      "[6] Predicted: chipmunks | Actual: chipmunks\n",
      "[7] Predicted: waterlily | Actual: waterlily\n",
      "[8] Predicted: whoops | Actual: whoops\n",
      "[9] Predicted: precis | Actual: precis\n",
      "[10] Predicted: babbler | Actual: babbler\n",
      "\n",
      " Word Accuracy: 63.77%\n",
      " Character Accuracy: 80.50%\n",
      "\n",
      "📚 Epoch 8: Loss = 0.2716\n",
      "[1] Predicted: slenderize | Actual: slenderize\n",
      "[2] Predicted: caria | Actual: carla\n",
      "[3] Predicted: bishops | Actual: bishops\n",
      "[4] Predicted: headbuitng | Actual: headbutting\n",
      "[5] Predicted: romanesque | Actual: romanesque\n",
      "[6] Predicted: chipmunks | Actual: chipmunks\n",
      "[7] Predicted: waterlily | Actual: waterlily\n",
      "[8] Predicted: whoops | Actual: whoops\n",
      "[9] Predicted: precis | Actual: precis\n",
      "[10] Predicted: babbler | Actual: babbler\n",
      "\n",
      " Word Accuracy: 65.30%\n",
      " Character Accuracy: 81.50%\n",
      "\n",
      "📚 Epoch 9: Loss = 0.2411\n",
      "[1] Predicted: slenderize | Actual: slenderize\n",
      "[2] Predicted: carla | Actual: carla\n",
      "[3] Predicted: bishops | Actual: bishops\n",
      "[4] Predicted: headeutting | Actual: headbutting\n",
      "[5] Predicted: romanesque | Actual: romanesque\n",
      "[6] Predicted: chipmunks | Actual: chipmunks\n",
      "[7] Predicted: wacerlily | Actual: waterlily\n",
      "[8] Predicted: whoops | Actual: whoops\n",
      "[9] Predicted: precis | Actual: precis\n",
      "[10] Predicted: babbler | Actual: babbler\n",
      "\n",
      " Word Accuracy: 64.58%\n",
      " Character Accuracy: 81.37%\n",
      "\n",
      "📚 Epoch 10: Loss = 0.2096\n",
      "[1] Predicted: slenderize | Actual: slenderize\n",
      "[2] Predicted: carla | Actual: carla\n",
      "[3] Predicted: bishops | Actual: bishops\n",
      "[4] Predicted: headeuiting | Actual: headbutting\n",
      "[5] Predicted: romanesque | Actual: romanesque\n",
      "[6] Predicted: chipmunks | Actual: chipmunks\n",
      "[7] Predicted: waterlily | Actual: waterlily\n",
      "[8] Predicted: whoops | Actual: whoops\n",
      "[9] Predicted: precis | Actual: precis\n",
      "[10] Predicted: babbler | Actual: babbler\n",
      "\n",
      " Word Accuracy: 65.00%\n",
      " Character Accuracy: 81.08%\n",
      "\n",
      "📚 Epoch 11: Loss = 0.1897\n",
      "[1] Predicted: slenderize | Actual: slenderize\n",
      "[2] Predicted: carua | Actual: carla\n",
      "[3] Predicted: bishops | Actual: bishops\n",
      "[4] Predicted: headbutting | Actual: headbutting\n",
      "[5] Predicted: romanesque | Actual: romanesque\n",
      "[6] Predicted: chpmunks | Actual: chipmunks\n",
      "[7] Predicted: waterlily | Actual: waterlily\n",
      "[8] Predicted: whoops | Actual: whoops\n",
      "[9] Predicted: precis | Actual: precis\n",
      "[10] Predicted: babbler | Actual: babbler\n",
      "\n",
      " Word Accuracy: 64.40%\n",
      " Character Accuracy: 80.21%\n",
      "\n",
      "📚 Epoch 12: Loss = 0.1645\n",
      "[1] Predicted: slenderize | Actual: slenderize\n",
      "[2] Predicted: carla | Actual: carla\n",
      "[3] Predicted: bishops | Actual: bishops\n",
      "[4] Predicted: headbuttng | Actual: headbutting\n",
      "[5] Predicted: romanesque | Actual: romanesque\n",
      "[6] Predicted: chipmunks | Actual: chipmunks\n",
      "[7] Predicted: waterlily | Actual: waterlily\n",
      "[8] Predicted: whoops | Actual: whoops\n",
      "[9] Predicted: precis | Actual: precis\n",
      "[10] Predicted: babbler | Actual: babbler\n",
      "\n",
      " Word Accuracy: 65.15%\n",
      " Character Accuracy: 81.39%\n",
      "\n",
      "📚 Epoch 13: Loss = 0.1512\n",
      "[1] Predicted: slenderize | Actual: slenderize\n",
      "[2] Predicted: carla | Actual: carla\n",
      "[3] Predicted: bishops | Actual: bishops\n",
      "[4] Predicted: headbutting | Actual: headbutting\n",
      "[5] Predicted: romanesque | Actual: romanesque\n",
      "[6] Predicted: chpmunks | Actual: chipmunks\n",
      "[7] Predicted: waterlily | Actual: waterlily\n",
      "[8] Predicted: whoops | Actual: whoops\n",
      "[9] Predicted: precis | Actual: precis\n",
      "[10] Predicted: babbler | Actual: babbler\n",
      "\n",
      " Word Accuracy: 66.02%\n",
      " Character Accuracy: 81.98%\n",
      "\n",
      "📚 Epoch 14: Loss = 0.1321\n",
      "[1] Predicted: slenderize | Actual: slenderize\n",
      "[2] Predicted: carla | Actual: carla\n",
      "[3] Predicted: bishops | Actual: bishops\n",
      "[4] Predicted: headbutting | Actual: headbutting\n",
      "[5] Predicted: romanesoue | Actual: romanesque\n",
      "[6] Predicted: chpmunks | Actual: chipmunks\n",
      "[7] Predicted: waterlily | Actual: waterlily\n",
      "[8] Predicted: whoops | Actual: whoops\n",
      "[9] Predicted: precis | Actual: precis\n",
      "[10] Predicted: babbler | Actual: babbler\n",
      "\n",
      " Word Accuracy: 65.17%\n",
      " Character Accuracy: 81.18%\n",
      "\n",
      "📚 Epoch 15: Loss = 0.1204\n",
      "[1] Predicted: slenderize | Actual: slenderize\n",
      "[2] Predicted: carla | Actual: carla\n",
      "[3] Predicted: bishops | Actual: bishops\n",
      "[4] Predicted: headbutting | Actual: headbutting\n",
      "[5] Predicted: romanesque | Actual: romanesque\n",
      "[6] Predicted: chpmunks | Actual: chipmunks\n",
      "[7] Predicted: waterlily | Actual: waterlily\n",
      "[8] Predicted: whoops | Actual: whoops\n",
      "[9] Predicted: precis | Actual: precis\n",
      "[10] Predicted: babbler | Actual: babbler\n",
      "\n",
      " Word Accuracy: 66.70%\n",
      " Character Accuracy: 82.51%\n",
      "\n",
      "📚 Epoch 16: Loss = 0.1082\n",
      "[1] Predicted: slenderize | Actual: slenderize\n",
      "[2] Predicted: carla | Actual: carla\n",
      "[3] Predicted: bishops | Actual: bishops\n",
      "[4] Predicted: headbutting | Actual: headbutting\n",
      "[5] Predicted: romanesque | Actual: romanesque\n",
      "[6] Predicted: chipmunks | Actual: chipmunks\n",
      "[7] Predicted: waterlily | Actual: waterlily\n",
      "[8] Predicted: whoops | Actual: whoops\n",
      "[9] Predicted: precis | Actual: precis\n",
      "[10] Predicted: babdler | Actual: babbler\n",
      "\n",
      " Word Accuracy: 65.77%\n",
      " Character Accuracy: 82.90%\n",
      "\n",
      "📚 Epoch 17: Loss = 0.0996\n",
      "[1] Predicted: slenderize | Actual: slenderize\n",
      "[2] Predicted: carla | Actual: carla\n",
      "[3] Predicted: bishops | Actual: bishops\n",
      "[4] Predicted: headbunting | Actual: headbutting\n",
      "[5] Predicted: romanesque | Actual: romanesque\n",
      "[6] Predicted: chipmunks | Actual: chipmunks\n",
      "[7] Predicted: waterlily | Actual: waterlily\n",
      "[8] Predicted: whoops | Actual: whoops\n",
      "[9] Predicted: precis | Actual: precis\n",
      "[10] Predicted: babbler | Actual: babbler\n",
      "\n",
      " Word Accuracy: 66.13%\n",
      " Character Accuracy: 82.39%\n",
      "\n",
      "📚 Epoch 18: Loss = 0.0907\n",
      "[1] Predicted: slenderize | Actual: slenderize\n",
      "[2] Predicted: caria | Actual: carla\n",
      "[3] Predicted: bishops | Actual: bishops\n",
      "[4] Predicted: headbutting | Actual: headbutting\n",
      "[5] Predicted: romanesque | Actual: romanesque\n",
      "[6] Predicted: chipmunks | Actual: chipmunks\n",
      "[7] Predicted: waterlily | Actual: waterlily\n",
      "[8] Predicted: whoops | Actual: whoops\n",
      "[9] Predicted: precis | Actual: precis\n",
      "[10] Predicted: babbler | Actual: babbler\n",
      "\n",
      " Word Accuracy: 66.10%\n",
      " Character Accuracy: 82.31%\n",
      "\n",
      "📚 Epoch 19: Loss = 0.0839\n",
      "[1] Predicted: slenderize | Actual: slenderize\n",
      "[2] Predicted: carla | Actual: carla\n",
      "[3] Predicted: bishops | Actual: bishops\n",
      "[4] Predicted: headbuiting | Actual: headbutting\n",
      "[5] Predicted: romanesque | Actual: romanesque\n",
      "[6] Predicted: chipmunks | Actual: chipmunks\n",
      "[7] Predicted: walerlily | Actual: waterlily\n",
      "[8] Predicted: whoops | Actual: whoops\n",
      "[9] Predicted: precis | Actual: precis\n",
      "[10] Predicted: babbler | Actual: babbler\n",
      "\n",
      " Word Accuracy: 65.47%\n",
      " Character Accuracy: 81.84%\n",
      "\n",
      "📚 Epoch 20: Loss = 0.0790\n",
      "[1] Predicted: slenderize | Actual: slenderize\n",
      "[2] Predicted: carla | Actual: carla\n",
      "[3] Predicted: bishops | Actual: bishops\n",
      "[4] Predicted: headeutting | Actual: headbutting\n",
      "[5] Predicted: romanesque | Actual: romanesque\n",
      "[6] Predicted: chipmunks | Actual: chipmunks\n",
      "[7] Predicted: waterlily | Actual: waterlily\n",
      "[8] Predicted: whoops | Actual: whoops\n",
      "[9] Predicted: precis | Actual: precis\n",
      "[10] Predicted: babdler | Actual: babbler\n",
      "\n",
      " Word Accuracy: 65.90%\n",
      " Character Accuracy: 82.66%\n",
      "\n",
      " Model saved as crnn_model.pth\n",
      "\n",
      "📚 Epoch 1: Loss = 3.0972\n",
      "[1] Predicted: s | Actual: shamrock\n",
      "[2] Predicted: a | Actual: hajjes\n",
      "[3] Predicted: a | Actual: ballasted\n",
      "[4] Predicted: s | Actual: splash\n",
      "[5] Predicted: e | Actual: pacesetter\n",
      "[6] Predicted: a | Actual: playpen\n",
      "[7] Predicted: a | Actual: punker\n",
      "[8] Predicted: a | Actual: aiding\n",
      "[9] Predicted: a | Actual: palmed\n",
      "[10] Predicted: os | Actual: cosmeticians\n",
      "\n",
      " Word Accuracy: 0.00%\n",
      " Character Accuracy: 1.55%\n",
      "\n",
      "📚 Epoch 2: Loss = 1.5482\n",
      "[1] Predicted: shamrocs | Actual: shamrock\n",
      "[2] Predicted: baies | Actual: hajjes\n",
      "[3] Predicted: oaries | Actual: ballasted\n",
      "[4] Predicted: splash | Actual: splash\n",
      "[5] Predicted: pacesetter | Actual: pacesetter\n",
      "[6] Predicted:  | Actual: playpen\n",
      "[7] Predicted: punker | Actual: punker\n",
      "[8] Predicted: atding | Actual: aiding\n",
      "[9] Predicted: pauned | Actual: palmed\n",
      "[10] Predicted: cosmeticians | Actual: cosmeticians\n",
      "\n",
      " Word Accuracy: 35.57%\n",
      " Character Accuracy: 62.77%\n",
      "\n",
      "📚 Epoch 3: Loss = 0.6907\n",
      "[1] Predicted: shamrock | Actual: shamrock\n",
      "[2] Predicted: baes | Actual: hajjes\n",
      "[3] Predicted: aakates | Actual: ballasted\n",
      "[4] Predicted: splash | Actual: splash\n",
      "[5] Predicted: pacesetter | Actual: pacesetter\n",
      "[6] Predicted: e | Actual: playpen\n",
      "[7] Predicted: punker | Actual: punker\n",
      "[8] Predicted: aiding | Actual: aiding\n",
      "[9] Predicted: palmed | Actual: palmed\n",
      "[10] Predicted: cosmeticians | Actual: cosmeticians\n",
      "\n",
      " Word Accuracy: 51.95%\n",
      " Character Accuracy: 73.11%\n",
      "\n",
      "📚 Epoch 4: Loss = 0.5303\n",
      "[1] Predicted: shamrocl | Actual: shamrock\n",
      "[2] Predicted: aes | Actual: hajjes\n",
      "[3] Predicted: ankiantad | Actual: ballasted\n",
      "[4] Predicted: splash | Actual: splash\n",
      "[5] Predicted: pacesetter | Actual: pacesetter\n",
      "[6] Predicted: oe | Actual: playpen\n",
      "[7] Predicted: punker | Actual: punker\n",
      "[8] Predicted: aiding | Actual: aiding\n",
      "[9] Predicted: palmed | Actual: palmed\n",
      "[10] Predicted: cosmeticians | Actual: cosmeticians\n",
      "\n",
      " Word Accuracy: 56.20%\n",
      " Character Accuracy: 75.93%\n",
      "\n",
      "📚 Epoch 5: Loss = 0.4399\n",
      "[1] Predicted: shamrock | Actual: shamrock\n",
      "[2] Predicted: aes | Actual: hajjes\n",
      "[3] Predicted: snaenstes | Actual: ballasted\n",
      "[4] Predicted: splash | Actual: splash\n",
      "[5] Predicted: pacesetter | Actual: pacesetter\n",
      "[6] Predicted: uree | Actual: playpen\n",
      "[7] Predicted: punker | Actual: punker\n",
      "[8] Predicted: aiding | Actual: aiding\n",
      "[9] Predicted: palmed | Actual: palmed\n",
      "[10] Predicted: cosmeticians | Actual: cosmeticians\n",
      "\n",
      " Word Accuracy: 59.02%\n",
      " Character Accuracy: 76.93%\n",
      "\n",
      "📚 Epoch 6: Loss = 0.3763\n",
      "[1] Predicted: shamrocl | Actual: shamrock\n",
      "[2] Predicted: bales | Actual: hajjes\n",
      "[3] Predicted: bhreted | Actual: ballasted\n",
      "[4] Predicted: splash | Actual: splash\n",
      "[5] Predicted: pacesetter | Actual: pacesetter\n",
      "[6] Predicted: iee | Actual: playpen\n",
      "[7] Predicted: punker | Actual: punker\n",
      "[8] Predicted: aiding | Actual: aiding\n",
      "[9] Predicted: palmed | Actual: palmed\n",
      "[10] Predicted: cosmeticians | Actual: cosmeticians\n",
      "\n",
      " Word Accuracy: 60.95%\n",
      " Character Accuracy: 78.35%\n",
      "\n",
      "📚 Epoch 7: Loss = 0.3260\n",
      "[1] Predicted: shamrocs | Actual: shamrock\n",
      "[2] Predicted: ales | Actual: hajjes\n",
      "[3] Predicted: aaceited | Actual: ballasted\n",
      "[4] Predicted: splash | Actual: splash\n",
      "[5] Predicted: pacesetter | Actual: pacesetter\n",
      "[6] Predicted: nree | Actual: playpen\n",
      "[7] Predicted: punker | Actual: punker\n",
      "[8] Predicted: aiding | Actual: aiding\n",
      "[9] Predicted: palmed | Actual: palmed\n",
      "[10] Predicted: cosmeticians | Actual: cosmeticians\n",
      "\n",
      " Word Accuracy: 62.43%\n",
      " Character Accuracy: 78.64%\n",
      "\n",
      "📚 Epoch 8: Loss = 0.2825\n",
      "[1] Predicted: shamrock | Actual: shamrock\n",
      "[2] Predicted: bles | Actual: hajjes\n",
      "[3] Predicted: arceatea | Actual: ballasted\n",
      "[4] Predicted: splash | Actual: splash\n",
      "[5] Predicted: pacesetter | Actual: pacesetter\n",
      "[6] Predicted: oree | Actual: playpen\n",
      "[7] Predicted: punker | Actual: punker\n",
      "[8] Predicted: aiding | Actual: aiding\n",
      "[9] Predicted: palmed | Actual: palmed\n",
      "[10] Predicted: cosmeticians | Actual: cosmeticians\n",
      "\n",
      " Word Accuracy: 63.22%\n",
      " Character Accuracy: 80.17%\n",
      "\n",
      "📚 Epoch 9: Loss = 0.2511\n",
      "[1] Predicted: shamroc | Actual: shamrock\n",
      "[2] Predicted: ales | Actual: hajjes\n",
      "[3] Predicted: anoeteg | Actual: ballasted\n",
      "[4] Predicted: splash | Actual: splash\n",
      "[5] Predicted: pacesetter | Actual: pacesetter\n",
      "[6] Predicted: ee | Actual: playpen\n",
      "[7] Predicted: punker | Actual: punker\n",
      "[8] Predicted: aiding | Actual: aiding\n",
      "[9] Predicted: palmed | Actual: palmed\n",
      "[10] Predicted: cosmeticians | Actual: cosmeticians\n",
      "\n",
      " Word Accuracy: 63.60%\n",
      " Character Accuracy: 80.79%\n",
      "\n",
      "📚 Epoch 10: Loss = 0.2184\n",
      "[1] Predicted: shamrock | Actual: shamrock\n",
      "[2] Predicted: rales | Actual: hajjes\n",
      "[3] Predicted: ahgited | Actual: ballasted\n",
      "[4] Predicted: splash | Actual: splash\n",
      "[5] Predicted: pacesetter | Actual: pacesetter\n",
      "[6] Predicted: wyee | Actual: playpen\n",
      "[7] Predicted: punker | Actual: punker\n",
      "[8] Predicted: aiding | Actual: aiding\n",
      "[9] Predicted: palmed | Actual: palmed\n",
      "[10] Predicted: cosmeticians | Actual: cosmeticians\n",
      "\n",
      " Word Accuracy: 64.78%\n",
      " Character Accuracy: 81.09%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import string\n",
    "\n",
    "# ================= Constants =================\n",
    "CHARS = string.ascii_lowercase + string.digits\n",
    "char_to_idx = {c: i for i, c in enumerate(CHARS)}\n",
    "idx_to_char = {i: c for c, i in char_to_idx.items()}\n",
    "NUM_CLASSES = len(CHARS) + 1  # +1 for CTC blank\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ============= MJSynth Dataset =============\n",
    "class MJSynthDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.Resize((32, 100)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "        self.samples = []\n",
    "        for img_name in os.listdir(root_dir):\n",
    "            if img_name.endswith(('.jpg', '.png')):\n",
    "                label = img_name.split('_')[0].lower()\n",
    "                if all(c in char_to_idx for c in label):\n",
    "                    self.samples.append((img_name, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name, word = self.samples[idx]\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        image = self.transform(image)\n",
    "        label = torch.tensor([char_to_idx[c] for c in word], dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "# ============= CRNN Model =============\n",
    "class CRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CRNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 1)),\n",
    "            nn.Conv2d(256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 1))\n",
    "        )\n",
    "        self.rnn = nn.LSTM(256 * 2, 256, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(512, NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        b, c, h, w = x.size()\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()\n",
    "        x = x.view(b, w, c * h)\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x.permute(1, 0, 2)\n",
    "\n",
    "# ============= Utils =============\n",
    "def collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    image_batch = torch.stack(images)\n",
    "    label_lengths = torch.tensor([len(l) for l in labels], dtype=torch.long)\n",
    "    labels_concat = torch.cat(labels)\n",
    "    return image_batch, labels_concat, label_lengths\n",
    "\n",
    "def decode(logits):\n",
    "    probs = torch.softmax(logits, dim=2)\n",
    "    _, preds = probs.max(2)\n",
    "    preds = preds.permute(1, 0)\n",
    "    results = []\n",
    "    for pred in preds:\n",
    "        string = ''\n",
    "        last = -1\n",
    "        for p in pred:\n",
    "            p = p.item()\n",
    "            if p != last and p != len(CHARS):\n",
    "                string += idx_to_char[p]\n",
    "            last = p\n",
    "        results.append(string)\n",
    "    return results\n",
    "\n",
    "# ============= Evaluation =============\n",
    "def evaluate_model(model, dataloader, max_samples=10, return_metrics=False):\n",
    "    model.eval()\n",
    "    correct_words = 0\n",
    "    correct_chars = 0\n",
    "    total_chars = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        count = 0\n",
    "        for images, labels, label_lengths in dataloader:\n",
    "            images = images.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            preds = decode(outputs)\n",
    "\n",
    "            label_idx = 0\n",
    "            actuals = []\n",
    "            for length in label_lengths:\n",
    "                actual = ''.join([idx_to_char[labels[i].item()] for i in range(label_idx, label_idx + length)])\n",
    "                actuals.append(actual)\n",
    "                label_idx += length\n",
    "\n",
    "            for pred, actual in zip(preds, actuals):\n",
    "                if count < max_samples:\n",
    "                    print(f\"[{count+1}] Predicted: {pred} | Actual: {actual}\")\n",
    "                if pred == actual:\n",
    "                    correct_words += 1\n",
    "                correct_chars += sum(p == a for p, a in zip(pred, actual))\n",
    "                total_chars += len(actual)\n",
    "                count += 1\n",
    "\n",
    "    total = len(dataloader.dataset)\n",
    "    word_acc = 100 * correct_words / total\n",
    "    char_acc = 100 * correct_chars / total_chars if total_chars > 0 else 0\n",
    "    print(f\"\\n Word Accuracy: {word_acc:.2f}%\")\n",
    "    print(f\" Character Accuracy: {char_acc:.2f}%\")\n",
    "\n",
    "    if return_metrics:\n",
    "        return word_acc, char_acc\n",
    "\n",
    "\n",
    "# ============= Training =============\n",
    "import matplotlib.pyplot as plt  # Add at the top\n",
    "\n",
    "def train_model():\n",
    "    dataset = MJSynthDataset(\"./mjsynth_subset\")\n",
    "    train_size = int(0.9 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    model = CRNN().to(DEVICE)\n",
    "    criterion = nn.CTCLoss(blank=len(CHARS))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    epoch_losses = []\n",
    "    epoch_word_accuracies = []\n",
    "    epoch_char_accuracies = []\n",
    "\n",
    "    for epoch in range(20):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for images, labels, label_lengths in train_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            output_len = torch.full((images.size(0),), outputs.size(0), dtype=torch.long).to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(outputs, labels, output_len, label_lengths)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        epoch_losses.append(avg_loss)\n",
    "        print(f\"\\n📚 Epoch {epoch + 1}: Loss = {avg_loss:.4f}\")\n",
    "\n",
    "        # Evaluate and record accuracy\n",
    "        word_acc, char_acc = evaluate_model(model, test_loader, return_metrics=True)\n",
    "        epoch_word_accuracies.append(word_acc)\n",
    "        epoch_char_accuracies.append(char_acc)\n",
    "\n",
    "    torch.save(model.state_dict(), \"crnn_model.pth\")\n",
    "    print(\"\\n Model saved as crnn_model.pth\")\n",
    "\n",
    "    # Return metrics for charting\n",
    "    return epoch_losses, epoch_word_accuracies, epoch_char_accuracies\n",
    "\n",
    "\n",
    "# ============= Run =============\n",
    "if __name__ == \"__main__\":\n",
    "    train_model()\n",
    "    losses, word_accs, char_accs = train_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838e72c8-304d-4f18-a831-882c519fc2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = list(range(1, len(losses) + 1))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, losses, label=\"Loss\", marker='o')\n",
    "plt.plot(epochs, word_accs, label=\"Word Accuracy (%)\", marker='x')\n",
    "plt.plot(epochs, char_accs, label=\"Char Accuracy (%)\", marker='s')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metric\")\n",
    "plt.title(\"Training Progress\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721e8c47-5e6f-460d-9002-3bb14cc45e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
